{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Torch related\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "from torch import optim\n",
    "\n",
    "# Style\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词汇\n",
    "vocab = np.load('../data/AOMP/vocab_dict.npy', allow_pickle=True).item()\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, pep_inputs, hla_inputs, labels):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.pep_inputs = pep_inputs\n",
    "        self.hla_inputs = hla_inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):  # 样本数\n",
    "        return len(self.pep_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pep_inputs[idx], self.hla_inputs[idx], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_data(data):\n",
    "    pep_max_len = 15  # peptide; enc_input max sequence length\n",
    "    hla_max_len = 34  # hla; dec_input(=dec_output) max sequence length\n",
    "\n",
    "    pep_inputs, hla_inputs, labels = [], [], []\n",
    "    for pep, hla, label in zip(data.peptide, data.HLA_sequence, data.label):\n",
    "        pep, hla = pep.ljust(pep_max_len, '-'), hla.ljust(hla_max_len, '-')\n",
    "        pep_input = [[vocab[n] for n in pep]]  # [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]\n",
    "        hla_input = [[vocab[n] for n in hla]]\n",
    "        pep_inputs.extend(pep_input)\n",
    "        hla_inputs.extend(hla_input)\n",
    "        labels.append(label)\n",
    "    return torch.LongTensor(pep_inputs), torch.LongTensor(hla_inputs), torch.LongTensor(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_with_loader(mode='train', batch_size=1024):\n",
    "    if mode == 'train':\n",
    "        data = pd.read_csv('../data/AOMP/train_data_fold0.csv', index_col=0)\n",
    "    if mode == 'val':\n",
    "        data = pd.read_csv('../data/AOMP/val_data_fold0.csv', index_col=0)\n",
    "\n",
    "    pep_inputs, hla_inputs, labels = make_data(data)\n",
    "    loader = DataLoader(MyDataSet(pep_inputs, hla_inputs, labels), batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    return data, pep_inputs, hla_inputs, labels, loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 1024):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        self._train_data = pd.read_csv('../data/AOMP/train_data_fold0.csv', index_col=0)\n",
    "        self._val_data = pd.read_csv('../data/AOMP/train_val_fold0.csv', index_col=0)\n",
    "\n",
    "        self.train_data = make_data(self._train_data)\n",
    "        self.train_data = make_data(self._val_data)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MyDataSet(*self.train_data), batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(MyDataSet(*self.val_data), batch_size, shuffle=False, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        '''\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    '''\n",
    "    seq_q: [batch_size, seq_len]\n",
    "    seq_k: [batch_size, seq_len]\n",
    "    seq_len could be src_len or it could be tgt_len\n",
    "    seq_len in seq_q and seq_len in seq_k maybe not equal\n",
    "    '''\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, len_k], False is masked\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # [batch_size, len_q, len_k]\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc(context) # [batch_size, len_q, d_model]\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        '''\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)  # Feature optimization block\n",
    "        return nn.LayerNorm(d_model).to(self.device)(output + residual)  # [batch_size, seq_len, d_model]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        '''\n",
    "        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, dec_self_attn_mask): # dec_inputs = enc_outputs\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        '''\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#         self.tgt_emb = nn.Embedding(d_model * 2, d_model)\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "        self.tgt_len = tgt_len\n",
    "\n",
    "    def forward(self, dec_inputs): # dec_inputs = enc_outputs (batch_size, peptide_hla_maxlen_sum, d_model)\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_intpus: [batch_size, src_len]\n",
    "        enc_outputs: [batsh_size, src_len, d_model]\n",
    "        '''\n",
    "#         dec_outputs = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device) # [batch_size, tgt_len, d_model]\n",
    "#         dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).cuda() # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_pad_mask = torch.LongTensor(np.zeros((dec_inputs.shape[0], tgt_len, tgt_len))).bool().to(device)\n",
    "\n",
    "        dec_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            dec_outputs, dec_self_attn = layer(dec_outputs, dec_self_attn_pad_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "\n",
    "        return dec_outputs, dec_self_attns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.   pep_encoder = Encoder().to(device)\n",
    "        self.hla_encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.tgt_len = tgt_len\n",
    "        self.projection = nn.Sequential(\n",
    "                                        nn.Linear(tgt_len * d_model, 256),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        nn.BatchNorm1d(256),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        #output layer\n",
    "                                        nn.Linear(64, 2)\n",
    "                                        ).to(device)\n",
    "\n",
    "    def forward(self, pep_inputs, hla_inputs):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        '''\n",
    "        # tensor to store decoder outputs\n",
    "        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "\n",
    "        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        pep_enc_outputs, pep_enc_self_attns = self.pep_encoder(pep_inputs)\n",
    "        hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs)\n",
    "        enc_outputs = torch.cat((pep_enc_outputs, hla_enc_outputs), 1) # concat pep & hla embedding\n",
    "\n",
    "        # dec_outpus: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\n",
    "        dec_outputs, dec_self_attns = self.decoder(enc_outputs)\n",
    "        dec_outputs = dec_outputs.view(dec_outputs.shape[0], -1) # Flatten [batch_size, tgt_len * d_model]\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), pep_enc_self_attns, hla_enc_self_attns, dec_self_attns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def performances(y_true, y_pred, y_prob, print_ = True):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel().tolist()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    try:\n",
    "        mcc = ((tp*tn) - (fn*fp)) / np.sqrt(np.float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    except:\n",
    "        print('MCC Error: ', (tp+fn)*(tn+fp)*(tp+fp)*(tn+fn))\n",
    "        mcc = np.nan\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "\n",
    "    try:\n",
    "        recall = tp / (tp+fn)\n",
    "    except:\n",
    "        recall = np.nan\n",
    "\n",
    "    try:\n",
    "        precision = tp / (tp+fp)\n",
    "    except:\n",
    "        precision = np.nan\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall / (precision+recall)\n",
    "    except:\n",
    "        f1 = np.nan\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    prec, reca, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr = auc(reca, prec)\n",
    "\n",
    "    if print_:\n",
    "        print('tn = {}, fp = {}, fn = {}, tp = {}'.format(tn, fp, fn, tp))\n",
    "        print('y_pred: 0 = {} | 1 = {}'.format(Counter(y_pred)[0], Counter(y_pred)[1]))\n",
    "        print('y_true: 0 = {} | 1 = {}'.format(Counter(y_true)[0], Counter(y_true)[1]))\n",
    "        print('auc={:.4f}|sensitivity={:.4f}|specificity={:.4f}|acc={:.4f}|mcc={:.4f}'.format(roc_auc, sensitivity, specificity, accuracy, mcc))\n",
    "        print('precision={:.4f}|recall={:.4f}|f1={:.4f}|aupr={:.4f}'.format(precision, recall, f1, aupr))\n",
    "\n",
    "    return (roc_auc, accuracy, mcc, f1, sensitivity, specificity, precision, recall, aupr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transfer(y_prob, threshold = 0.5):\n",
    "    # 置信 50\n",
    "    return np.array([[0, 1][x > threshold] for x in y_prob])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f_mean = lambda l: sum(l)/len(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def performances_to_pd(performances_list):\n",
    "    metrics_name = ['roc_auc', 'accuracy', 'mcc', 'f1', 'sensitivity', 'specificity', 'precision', 'recall', 'aupr']\n",
    "\n",
    "    performances_pd = pd.DataFrame(performances_list, columns = metrics_name)\n",
    "    performances_pd.loc['mean'] = performances_pd.mean(axis = 0)\n",
    "    performances_pd.loc['std'] = performances_pd.std(axis = 0)\n",
    "\n",
    "    return performances_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    time_train_ep = 0\n",
    "    model.train()\n",
    "    y_true_train_list, y_prob_train_list = [], []\n",
    "    loss_train_list, dec_attns_train_list = [], []\n",
    "    for train_pep_inputs, train_hla_inputs, train_labels in tqdm(train_loader):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        train_outputs: [batch_size, 2]\n",
    "        '''\n",
    "        train_pep_inputs, train_hla_inputs, train_labels = train_pep_inputs.to(device), train_hla_inputs.to(device), train_labels.to(device)\n",
    "\n",
    "        t1 = time.time()\n",
    "        train_outputs, _, _, train_dec_self_attns = model(train_pep_inputs,\n",
    "                                                                                                        train_hla_inputs)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        time_train_ep += time.time() - t1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true_train = train_labels.cpu().numpy()\n",
    "        y_prob_train = nn.Softmax(dim = 1)(train_outputs)[:, 1].cpu().detach().numpy()\n",
    "\n",
    "        y_true_train_list.extend(y_true_train)\n",
    "        y_prob_train_list.extend(y_prob_train)\n",
    "        loss_train_list.append(train_loss)\n",
    "#         dec_attns_train_list.append(train_dec_self_attns)\n",
    "\n",
    "    y_pred_train_list = transfer(y_prob_train_list, threshold)\n",
    "    ys_train = (y_true_train_list, y_pred_train_list, y_prob_train_list)\n",
    "\n",
    "    print('Fold-{}****Train (Ep avg): Epoch-{}/{} | Loss = {:.4f} | Time = {:.4f} sec'.format(fold, epoch, epochs, f_mean(loss_train_list), time_train_ep))\n",
    "    metrics_train = performances(y_true_train_list, y_pred_train_list, y_prob_train_list, print_ = True)\n",
    "\n",
    "    return ys_train, loss_train_list, metrics_train, time_train_ep#, dec_attns_train_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_step(model, val_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    torch.manual_seed(19961231)\n",
    "    torch.cuda.manual_seed(19961231)\n",
    "    with torch.no_grad():\n",
    "        loss_val_list, dec_attns_val_list = [], []\n",
    "        y_true_val_list, y_prob_val_list = [], []\n",
    "        for val_pep_inputs, val_hla_inputs, val_labels in tqdm(val_loader):\n",
    "            val_pep_inputs, val_hla_inputs, val_labels = val_pep_inputs.to(device), val_hla_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs, _, _, val_dec_self_attns = model(val_pep_inputs, val_hla_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            y_true_val = val_labels.cpu().numpy()\n",
    "            y_prob_val = nn.Softmax(dim = 1)(val_outputs)[:, 1].cpu().detach().numpy()\n",
    "\n",
    "            y_true_val_list.extend(y_true_val)\n",
    "            y_prob_val_list.extend(y_prob_val)\n",
    "            loss_val_list.append(val_loss)\n",
    "#             dec_attns_val_list.append(val_dec_self_attns)\n",
    "\n",
    "        y_pred_val_list = transfer(y_prob_val_list, threshold)\n",
    "        ys_val = (y_true_val_list, y_pred_val_list, y_prob_val_list)\n",
    "\n",
    "        print('Fold-{} ****Test  Epoch-{}/{}: Loss = {:.6f}'.format(fold, epoch, epochs, f_mean(loss_val_list)))\n",
    "        metrics_val = performances(y_true_val_list, y_pred_val_list, y_prob_val_list, print_ = True)\n",
    "    return ys_val, loss_val_list, metrics_val#, dec_attns_val_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transformer Parameters\n",
    "d_model = 64  # Embedding Size\n",
    "d_ff = 512 # FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_layers = 1  # number of Encoder of Decoder Layer\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 50\n",
    "threshold = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_heads = 4\n",
    "\n",
    "ys_train_fold_dict, ys_val_fold_dict = {}, {}\n",
    "train_fold_metrics_list, val_fold_metrics_list = [], []\n",
    "independent_fold_metrics_list, external_fold_metrics_list, ys_independent_fold_dict, ys_external_fold_dict = [], [], {}, {}\n",
    "attns_train_fold_dict, attns_val_fold_dict, attns_independent_fold_dict, attns_external_fold_dict = {}, {}, {}, {}\n",
    "loss_train_fold_dict, loss_val_fold_dict, loss_independent_fold_dict, loss_external_fold_dict = {}, {}, {}, {}\n",
    "\n",
    "\n",
    "train_data, train_pep_inputs, train_hla_inputs, train_labels, train_loader = data_with_loader(mode = 'train', batch_size = batch_size)\n",
    "val_data, val_pep_inputs, val_hla_inputs, val_labels, val_loader = data_with_loader(mode = 'val',  batch_size = batch_size)\n",
    "\n",
    "model = Transformer().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)#, momentum = 0.99)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://keras.io/examples/graph/mpnn-molecular-graphs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Temporary suppress tf logs\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "\n",
    "# Temporary suppress warnings and RDKit logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   smiles  p_np\n0       CC(C)C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@...     0\n1       CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O...     1\n2       CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...     0\n3       CSCC[C@H](N)C(=O)N[C@H](C(=O)N[C@@H](Cc1ccccc1...     0\n4       CC(C)C[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](N)...     0\n...                                                   ...   ...\n574653  C[C@@H](O)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@H...     0\n574654  CC[C@H](C)[C@H](N)C(=O)N[C@@H](CCSC)C(=O)N[C@@...     1\n574655  CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@H](CO)NC(=...     1\n574656  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...     0\n574657  CC[C@H](C)[C@H](N)C(=O)N1CCC[C@H]1C(=O)N[C@@H]...     0\n\n[574658 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smiles</th>\n      <th>p_np</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CC(C)C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CSCC[C@H](N)C(=O)N[C@H](C(=O)N[C@@H](Cc1ccccc1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CC(C)C[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](N)...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>574653</th>\n      <td>C[C@@H](O)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@H...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>574654</th>\n      <td>CC[C@H](C)[C@H](N)C(=O)N[C@@H](CCSC)C(=O)N[C@@...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>574655</th>\n      <td>CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@H](CO)NC(=...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>574656</th>\n      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>574657</th>\n      <td>CC[C@H](C)[C@H](N)C(=O)N1CCC[C@H]1C(=O)N[C@@H]...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>574658 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path='../data/AOMP_SMILES/train.txt'\n",
    "df = pd.read_csv(csv_path, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   smiles  p_np\n0       CC(C)C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@...     0\n1       CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O...     1\n2       CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...     0\n3       CSCC[C@H](N)C(=O)N[C@H](C(=O)N[C@@H](Cc1ccccc1...     0\n4       CC(C)C[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](N)...     0\n...                                                   ...   ...\n479534  CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@@H](NC(=O)[C@@...     0\n479535  C[C@@H](O)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@H...     0\n479536  CC[C@H](C)[C@H](N)C(=O)N[C@@H](CCSC)C(=O)N[C@@...     1\n479537  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...     0\n479538  CC[C@H](C)[C@H](N)C(=O)N1CCC[C@H]1C(=O)N[C@@H]...     0\n\n[479539 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smiles</th>\n      <th>p_np</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CC(C)C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CSCC[C@H](N)C(=O)N[C@H](C(=O)N[C@@H](Cc1ccccc1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CC(C)C[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](N)...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>479534</th>\n      <td>CSCC[C@H](NC(=O)[C@@H](NC(=O)[C@@H](NC(=O)[C@@...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>479535</th>\n      <td>C[C@@H](O)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@H...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>479536</th>\n      <td>CC[C@H](C)[C@H](N)C(=O)N[C@@H](CCSC)C(=O)N[C@@...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>479537</th>\n      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>479538</th>\n      <td>CC[C@H](C)[C@H](N)C(=O)N1CCC[C@H]1C(=O)N[C@@H]...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>479539 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['smiles']).reset_index(drop=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df=df[:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Featurizer:\n",
    "    def __init__(self, allowable_sets):\n",
    "        self.dim = 0\n",
    "        self.features_mapping = {}\n",
    "        for k, s in allowable_sets.items():\n",
    "            s = sorted(list(s))\n",
    "            self.features_mapping[k] = dict(zip(s, range(self.dim, len(s) + self.dim)))\n",
    "            self.dim += len(s)\n",
    "\n",
    "    def encode(self, inputs):\n",
    "        output = np.zeros((self.dim,))\n",
    "        for name_feature, feature_mapping in self.features_mapping.items():\n",
    "            feature = getattr(self, name_feature)(inputs)\n",
    "            if feature not in feature_mapping:\n",
    "                continue\n",
    "            output[feature_mapping[feature]] = 1.0\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AtomFeaturizer(Featurizer):\n",
    "    def __init__(self, allowable_sets):\n",
    "        super().__init__(allowable_sets)\n",
    "\n",
    "    def symbol(self, atom):\n",
    "        return atom.GetSymbol()\n",
    "\n",
    "    def n_valence(self, atom):\n",
    "        return atom.GetTotalValence()\n",
    "\n",
    "    def n_hydrogens(self, atom):\n",
    "        return atom.GetTotalNumHs()\n",
    "\n",
    "    def hybridization(self, atom):\n",
    "        return atom.GetHybridization().name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BondFeaturizer(Featurizer):\n",
    "    def __init__(self, allowable_sets):\n",
    "        super().__init__(allowable_sets)\n",
    "        self.dim += 1\n",
    "\n",
    "    def encode(self, bond):\n",
    "        output = np.zeros((self.dim,))\n",
    "        if bond is None:\n",
    "            output[-1] = 1.0\n",
    "            return output\n",
    "        output = super().encode(bond)\n",
    "        return output\n",
    "\n",
    "    def bond_type(self, bond):\n",
    "        return bond.GetBondType().name.lower()\n",
    "\n",
    "    def conjugated(self, bond):\n",
    "        return bond.GetIsConjugated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "atom_featurizer = AtomFeaturizer(\n",
    "    allowable_sets={\n",
    "        \"symbol\": {\"B\", \"Br\", \"C\", \"Ca\", \"Cl\", \"F\", \"H\", \"I\", \"N\", \"Na\", \"O\", \"P\", \"S\"},\n",
    "        \"n_valence\": {0, 1, 2, 3, 4, 5, 6},\n",
    "        \"n_hydrogens\": {0, 1, 2, 3, 4},\n",
    "        \"hybridization\": {\"s\", \"sp\", \"sp2\", \"sp3\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bond_featurizer = BondFeaturizer(\n",
    "    allowable_sets={\n",
    "        \"bond_type\": {\"single\", \"double\", \"triple\", \"aromatic\"},\n",
    "        \"conjugated\": {True, False},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def molecule_from_smiles(smiles):\n",
    "    # MolFromSmiles(m, sanitize=True) should be equivalent to\n",
    "    # MolFromSmiles(m, sanitize=False) -> SanitizeMol(m) -> AssignStereochemistry(m, ...)\n",
    "    molecule = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "\n",
    "    # If sanitization is unsuccessful, catch the error, and try again without\n",
    "    # the sanitization step that caused the error\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        Chem.SanitizeMol(molecule, sanitizeOps=Chem.SanitizeFlags.SANITIZE_ALL ^ flag)\n",
    "\n",
    "    Chem.AssignStereochemistry(molecule, cleanIt=True, force=True)\n",
    "    return molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def graph_from_molecule(molecule):\n",
    "    # Initialize graph\n",
    "    atom_features = []\n",
    "    bond_features = []\n",
    "    pair_indices = []\n",
    "\n",
    "    for i, atom in enumerate(molecule.GetAtoms()):\n",
    "\n",
    "        atom_features.append(atom_featurizer.encode(atom))\n",
    "\n",
    "        # Add self-loops\n",
    "        pair_indices.append([atom.GetIdx(), atom.GetIdx()])\n",
    "        bond_features.append(bond_featurizer.encode(None))\n",
    "\n",
    "        for neighbor in atom.GetNeighbors():\n",
    "            bond = molecule.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
    "            pair_indices.append([atom.GetIdx(), neighbor.GetIdx()])\n",
    "            bond_features.append(bond_featurizer.encode(bond))\n",
    "\n",
    "    return np.array(atom_features), np.array(bond_features), np.array(pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def graphs_from_smiles(smiles_list):\n",
    "    # Initialize graphs\n",
    "    atom_features_list = []\n",
    "    bond_features_list = []\n",
    "    pair_indices_list = []\n",
    "\n",
    "    with tqdm(smiles_list, total=len(smiles_list)) as pbar:\n",
    "        for smiles in pbar:\n",
    "            molecule = molecule_from_smiles(smiles)\n",
    "            atom_features, bond_features, pair_indices = graph_from_molecule(molecule)  # slow\n",
    "\n",
    "            atom_features_list.append(atom_features)\n",
    "            bond_features_list.append(bond_features)\n",
    "            pair_indices_list.append(pair_indices)\n",
    "\n",
    "    # Convert lists to ragged tensors for tf.data.Dataset later on\n",
    "    return (\n",
    "        tf.ragged.constant(np.array(atom_features_list), dtype=tf.float32),\n",
    "        tf.ragged.constant(np.array(bond_features_list), dtype=tf.float32),\n",
    "        tf.ragged.constant(np.array(pair_indices_list), dtype=tf.int64),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 ms, sys: 0 ns, total: 1.17 ms\n",
      "Wall time: 705 µs\n",
      "CPU times: user 13 µs, sys: 0 ns, total: 13 µs\n",
      "Wall time: 15.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/8000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6904ae8990ff47fa87aa26fbfc70344f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 512 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n",
      "CPU times: user 960 µs, sys: 17 µs, total: 977 µs\n",
      "Wall time: 967 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Shuffle array of indices ranging from 0 to 2049\n",
    "permuted_indices = np.random.permutation(np.arange(df.shape[0]))\n",
    "\n",
    "# Train set: 80 % of data\n",
    "train_index = permuted_indices[: int(df.shape[0] * 0.8)]\n",
    "x_train = graphs_from_smiles(df.iloc[train_index].smiles)\n",
    "y_train = df.iloc[train_index].p_np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.tools.my_pickle import to_pickle\n",
    "# to_pickle(x_train, '../.cache/x_train.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Valid set: 10 % of data\n",
    "valid_index = permuted_indices[int(df.shape[0] * 0.8) : int(df.shape[0] * 0.9)]\n",
    "x_valid = graphs_from_smiles(df.iloc[valid_index].smiles)\n",
    "y_valid = df.iloc[valid_index].p_np\n",
    "\n",
    "# Test set: 10 % of data\n",
    "test_index = permuted_indices[int(df.shape[0] * 0.9) :]\n",
    "x_test = graphs_from_smiles(df.iloc[test_index].smiles)\n",
    "y_test = df.iloc[test_index].p_np\n",
    "\n",
    "# to_pickle(x_train, '../.cache/x_train.pkl')\n",
    "# to_pickle(x_train, '../.cache/x_train.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 这里对应索引\n",
    "print(f\"Idx:\\t{df.index[100]}\\nSMILES:\\t{df.smiles[100]}\\nBBBP:\\t{df.p_np[100]}\")\n",
    "molecule = molecule_from_smiles(df.iloc[100].smiles)\n",
    "print(\"Molecule:\")\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph = graph_from_molecule(molecule)\n",
    "print(\"Graph (including self-loops):\")\n",
    "print(\"\\tatom features\\t\", graph[0].shape)\n",
    "print(\"\\tbond features\\t\", graph[1].shape)\n",
    "print(\"\\tpair indices\\t\", graph[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_batch(x_batch, y_batch):\n",
    "    \"\"\"Merges (sub)graphs of batch into a single global (disconnected) graph\n",
    "    \"\"\"\n",
    "\n",
    "    atom_features, bond_features, pair_indices = x_batch\n",
    "\n",
    "    # Obtain number of atoms and bonds for each graph (molecule)\n",
    "    num_atoms = atom_features.row_lengths()\n",
    "    num_bonds = bond_features.row_lengths()\n",
    "\n",
    "    # Obtain partition indices (molecule_indicator), which will be used to\n",
    "    # gather (sub)graphs from global graph in model later on\n",
    "    molecule_indices = tf.range(len(num_atoms))\n",
    "    molecule_indicator = tf.repeat(molecule_indices, num_atoms)\n",
    "\n",
    "    # Merge (sub)graphs into a global (disconnected) graph. Adding 'increment' to\n",
    "    # 'pair_indices' (and merging ragged tensors) actualizes the global graph\n",
    "    gather_indices = tf.repeat(molecule_indices[:-1], num_bonds[1:])\n",
    "    increment = tf.cumsum(num_atoms[:-1])\n",
    "    increment = tf.pad(tf.gather(increment, gather_indices), [(num_bonds[0], 0)])\n",
    "    pair_indices = pair_indices.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
    "    pair_indices = pair_indices + increment[:, tf.newaxis]\n",
    "    atom_features = atom_features.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
    "    bond_features = bond_features.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
    "\n",
    "    return (atom_features, bond_features, pair_indices, molecule_indicator), y_batch\n",
    "\n",
    "\n",
    "def MPNNDataset(X, y, batch_size=32, shuffle=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, (y)))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "    return dataset.batch(batch_size).map(prepare_batch, -1).prefetch(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EdgeNetwork(layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.atom_dim = input_shape[0][-1]\n",
    "        self.bond_dim = input_shape[1][-1]\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.bond_dim, self.atom_dim * self.atom_dim),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.atom_dim * self.atom_dim), initializer=\"zeros\", name=\"bias\",\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        atom_features, bond_features, pair_indices = inputs\n",
    "\n",
    "        # Apply linear transformation to bond features\n",
    "        bond_features = tf.matmul(bond_features, self.kernel) + self.bias\n",
    "\n",
    "        # Reshape for neighborhood aggregation later\n",
    "        bond_features = tf.reshape(bond_features, (-1, self.atom_dim, self.atom_dim))\n",
    "\n",
    "        # Obtain atom features of neighbors\n",
    "        atom_features_neighbors = tf.gather(atom_features, pair_indices[:, 1])\n",
    "        atom_features_neighbors = tf.expand_dims(atom_features_neighbors, axis=-1)\n",
    "\n",
    "        # Apply neighborhood aggregation\n",
    "        transformed_features = tf.matmul(bond_features, atom_features_neighbors)\n",
    "        transformed_features = tf.squeeze(transformed_features, axis=-1)\n",
    "        aggregated_features = tf.math.unsorted_segment_sum(\n",
    "            transformed_features,\n",
    "            pair_indices[:, 0],\n",
    "            num_segments=tf.shape(atom_features)[0],\n",
    "        )\n",
    "        return aggregated_features\n",
    "\n",
    "\n",
    "class MessagePassing(layers.Layer):\n",
    "    def __init__(self, units, steps=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.steps = steps\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.atom_dim = input_shape[0][-1]\n",
    "        self.message_step = EdgeNetwork()\n",
    "        self.pad_length = max(0, self.units - self.atom_dim)\n",
    "        self.update_step = layers.GRUCell(self.atom_dim + self.pad_length)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        atom_features, bond_features, pair_indices = inputs\n",
    "\n",
    "        # Pad atom features if number of desired units exceeds atom_features dim.\n",
    "        # Alternatively, a dense layer could be used here.\n",
    "        atom_features_updated = tf.pad(atom_features, [(0, 0), (0, self.pad_length)])\n",
    "\n",
    "        # Perform a number of steps of message passing\n",
    "        for i in range(self.steps):\n",
    "            # Aggregate information from neighbors\n",
    "            atom_features_aggregated = self.message_step(\n",
    "                [atom_features_updated, bond_features, pair_indices]\n",
    "            )\n",
    "\n",
    "            # Update node state via a step of GRU\n",
    "            atom_features_updated, _ = self.update_step(\n",
    "                atom_features_aggregated, atom_features_updated\n",
    "            )\n",
    "        return atom_features_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PartitionPadding(layers.Layer):\n",
    "    def __init__(self, batch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        atom_features, molecule_indicator = inputs\n",
    "\n",
    "        # Obtain subgraphs\n",
    "        atom_features_partitioned = tf.dynamic_partition(\n",
    "            atom_features, molecule_indicator, self.batch_size\n",
    "        )\n",
    "\n",
    "        # Pad and stack subgraphs\n",
    "        num_atoms = [tf.shape(f)[0] for f in atom_features_partitioned]\n",
    "        max_num_atoms = tf.reduce_max(num_atoms)\n",
    "        atom_features_stacked = tf.stack(\n",
    "            [\n",
    "                tf.pad(f, [(0, max_num_atoms - n), (0, 0)])\n",
    "                for f, n in zip(atom_features_partitioned, num_atoms)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # Remove empty subgraphs (usually for last batch in dataset)\n",
    "        gather_indices = tf.where(tf.reduce_sum(atom_features_stacked, (1, 2)) != 0)\n",
    "        gather_indices = tf.squeeze(gather_indices, axis=-1)\n",
    "        return tf.gather(atom_features_stacked, gather_indices, axis=0)\n",
    "\n",
    "\n",
    "class TransformerEncoderReadout(layers.Layer):\n",
    "    def __init__(\n",
    "        self, num_heads=8, embed_dim=64, dense_dim=512, batch_size=32, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.partition_padding = PartitionPadding(batch_size)\n",
    "        self.attention = layers.MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.average_pooling = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.partition_padding(inputs)\n",
    "        padding_mask = tf.reduce_any(tf.not_equal(x, 0.0), axis=-1)\n",
    "        padding_mask = padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        attention_output = self.attention(x, x, attention_mask=padding_mask)\n",
    "        proj_input = self.layernorm_1(x + attention_output)\n",
    "        proj_output = self.layernorm_2(proj_input + self.dense_proj(proj_input))\n",
    "        return self.average_pooling(proj_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MPNNModel(\n",
    "    atom_dim,\n",
    "    bond_dim,\n",
    "    batch_size=32,\n",
    "    message_units=64,\n",
    "    message_steps=4,\n",
    "    num_attention_heads=8,\n",
    "    dense_units=512,\n",
    "):\n",
    "\n",
    "    atom_features = layers.Input((atom_dim), dtype=\"float32\", name=\"atom_features\")\n",
    "    bond_features = layers.Input((bond_dim), dtype=\"float32\", name=\"bond_features\")\n",
    "    pair_indices = layers.Input((2), dtype=\"int32\", name=\"pair_indices\")\n",
    "    molecule_indicator = layers.Input((), dtype=\"int32\", name=\"molecule_indicator\")\n",
    "\n",
    "    x = MessagePassing(message_units, message_steps)(\n",
    "        [atom_features, bond_features, pair_indices]\n",
    "    )\n",
    "\n",
    "    x = TransformerEncoderReadout(\n",
    "        num_attention_heads, message_units, dense_units, batch_size\n",
    "    )([x, molecule_indicator])\n",
    "\n",
    "    x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs=[atom_features, bond_features, pair_indices, molecule_indicator],\n",
    "        outputs=[x],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "mpnn = MPNNModel(\n",
    "    atom_dim=x_train[0][0][0].shape[0], bond_dim=x_train[1][0][0].shape[0],\n",
    ")\n",
    "\n",
    "mpnn.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    metrics=[keras.metrics.AUC(name=\"AUC\")],\n",
    ")\n",
    "\n",
    "keras.utils.plot_model(mpnn, show_dtype=True, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MPNNDataset(x_train, y_train)\n",
    "valid_dataset = MPNNDataset(x_valid, y_valid)\n",
    "test_dataset = MPNNDataset(x_test, y_test)\n",
    "\n",
    "history = mpnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=40,\n",
    "    verbose=2,\n",
    "    class_weight={0: 2.0, 1: 0.5},\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"AUC\"], label=\"train AUC\")\n",
    "plt.plot(history.history[\"val_AUC\"], label=\"valid AUC\")\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"AUC\", fontsize=16)\n",
    "plt.legend(fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "molecules = [molecule_from_smiles(df.smiles.values[index]) for index in test_index]\n",
    "y_true = [df.p_np.values[index] for index in test_index]\n",
    "y_pred = tf.squeeze(mpnn.predict(test_dataset), axis=1)\n",
    "\n",
    "legends = [f\"y_true/y_pred = {y_true[i]}/{y_pred[i]:.2f}\" for i in range(len(y_true))]\n",
    "MolsToGridImage(molecules, molsPerRow=4, legends=legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a961c826e6defbd920b4ccaf3066473f03ebad02ee5c784d8ab77217a561cca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}